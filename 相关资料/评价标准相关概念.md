## 深度学习中的一些评价标准

> [参考](https://www.cnblogs.com/gatherstars/p/6084696.html)

### 1、ROC曲线

Receiver operating characteristic curve/sensitivity curve 。现实中**样本在不同类别上的不均衡分布**(class distribution imbalance problem)。使得accuracy这样的传统的度量标准不能恰当的反应分类器的performance。

 **ROC曲线的主要用途有两个**：**1）评价某个/多个指标对两类被试（如病人和健康人）分类/诊断的效果**。通过画出某个指标的ROC曲线就可以很明确地看出其分类/诊断效果的好坏；另外，可以同时画出多个指标的ROC曲线并计算各自的AUC（area under ROC，ROC曲线下的面积），就可以知道哪个指标的分类/诊断效果更好。**2）寻找最佳的指标阈值使得分类效果最佳。** 

举个例子：测试样本中有A类样本90个，B 类样本10个。分类器C1把所有的测试样本都分成了A类，分类器C2把A类的90个样本分对了70个，B类的10个样本分对了5个。则C1的分类精度为 90%，C2的分类精度为75%。但是，显然C2更有用些。另外，在一些分类问题中犯不同的错误代价是不同的(cost sensitive learning)。这样，默认0.5为分类阈值的传统做法也显得不恰当了。

为了解决上述问题，人们从医疗分析领域引入了一种新的分类模型performance评判方法——ROC分析。

ROC分析的主要分析工具是一个画在二维平面的曲线。平面的**横坐标是false positive rate（FPR） FPR=FP/(FP+TN)** ，**纵坐标是true positive rate （TPR） TPR=TP/(TP+FN) **。 对某个分类器而言，我们可以根据其在测试样本上的表现得到一个TPR和FPR点对。这样，此分类器就可以映射成ROC平面上的一个点。调整这个分类器分类时候使用的阈值，我们就可以得到一个经过(0, 0)，(1, 1)的曲线，这就是此分类器的ROC曲线。 

 ![img](https://images2015.cnblogs.com/blog/788753/201611/788753-20161121105324471-798238482.png) 

TPR：在所有实际为阳性的样本中，被正确地判断为阳性之比率。TPR=TP/(TP+FN)

FPR：在所有实际为阴性的样本中，被错误地判断为阳性之比率。FPR=FP/(FP+TN)

在医学诊断中，判断有病的样本。那么尽量把有病的揪出来是主要任务，也就是第一个指标TPR，要越高越好。而把没病的样本误诊为有病的，也就是第二个指标FPR，要越低越好。不难发现，这两个指标之间是相互制约的。如果某个医生对于有病的症状比较敏感，稍微的小症状都判断为有病，那么他的第一个指标应该会很高，但是第二个指标也就相应地变高。最极端的情况下，他把所有的样本都看做有病，那么第一个指标达到1，第二个指标也为1。 

 ![img](https://images2015.cnblogs.com/blog/788753/201611/788753-20161121105504034-991875038.png) 

从图形上来观察，曲线越靠近左上的（1，0）点效果越好，等价于AUC值越大。

### 2、AUC值

area under of curve 。是一种用来**度量分类模型的一个标准/标志分类器的好坏**。AUC值得大小就是处在ROC Curve下方得那部分面积得大小。通常AUC得值介于0.5-1.0之间，较大的AUC代表了较好的performance。

**AUC = 1**，是完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。

**0.5 < AUC < 1**，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。

**AUC = 0.5**，跟随机猜测一样（例：丢铜板），模型没有预测价值。

**AUC < 0.5**，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。

### 3、准确率（PPV）

Precision和recall是广泛用于信息检索和统计学分类领域的两个度量值，用来评价结果的质量。

precision是指正确识别的总数/识别的总数。

### 4、召回率（Recall）

recall是指正确识别的总数/测试集中存在的个体总数

### 5、F1值

F1值是PPV和Recall的平均值

### 6、敏感度Sensitivity

 ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190807002722374.png) 

TP：P表示你预测的Positive，T（True）表示你预测正确，TP表示你把正样本预测为正样本
FP：P表示你预测的Positive，F（False）表示你预测错误，FP表示你把负样本预测为正样本
TN：N表示你预测的Negative，T（True）表示你预测正确，TN表示你把负样本预测为负样本
FN：N表示你预测的Negative，F（False）表示你预测错误，FP表示你把正样本预测为负样本

**precision = TP / (TP + FP)**
precision表示精确率，针对的是你所预测的正样本中，预测正确的正样本（即把正样本预测为正样本）占的比例。精确率越高，表示找的越准。

**recall = TP / (TP + FN)**
recall表示召回率， 针对的是所有的正样本中，预测正确的正样本（即把正样本预测为正样本）占的比例。召回率越高，表示找的越全。

**sensitivity = TP / (TP + FN)**
sensitivity 表示灵敏度，表示对正例的预测能力（越高越好），数值上等于召回率。

**specificity = TN / (TN + FP)**
specificity 表示特异度，表示对负例的预测能力（越高越好）。

**可以看到sensitivity 、specificity 就是归一化混淆矩阵对角线上的值。**

**F1 = 2 \* precision \* recall / (precision + recall)** 

### 7、inter-patients

对不同的病人（record）进行特征提取和分类 

### 8、intra-patients

直接对所有 records 中的数据进行随机分配，一部分为训练集，另外为测试集。 

通过训练同一个病人的部分心拍，再对同一个病人的其余心拍进行测试，来实现的高精确度分类。 